# Conversational BI RAG Backend

A Python backend for a Conversational Business Intelligence (BI) system powered by Retrieval-Augmented Generation (RAG). This backend uses FastAPI, OpenAI, and ChromaDB to convert natural language questions into SQL queries and return insights as streaming text or graphs.

## ğŸ§  Key Features

- ğŸ” **Natural Language to SQL**: Converts user questions into PostgreSQL queries using OpenAI.
- ğŸ“Š **Conversational BI**: Supports both textual and graph-based data responses.
- ğŸ” **Streaming API (SSE)**: Delivers word-by-word responses in real-time.
- ğŸ“‚ **RAG-Powered**: Uses schema, sample queries, filters, and metrics embedded via ChromaDB.
- ğŸ§  **Embeddings**: Generates and stores vector embeddings from documents for context-aware responses.



## ğŸš€ Tech Stack

- **FastAPI** â€“ Lightweight, fast backend framework
- **PostgreSQL** â€“ Data source for BI queries
- **ChromaDB** â€“ Local vector store for embeddings
- **OpenAI API** â€“ SQL generation, response synthesis
- **Docker Compose** â€“ Containerized deployment
- **SSE/WebSocket** â€“ Real-time data streaming (SSE implemented)



## ğŸ› ï¸ Project Structure

    # Conversational BI RAG Backend

A Python backend for a Conversational Business Intelligence (BI) system powered by Retrieval-Augmented Generation (RAG). This backend uses FastAPI, OpenAI, and ChromaDB to convert natural language questions into SQL queries and return insights as streaming text or graphs.

## ğŸ§  Key Features

- ğŸ” **Natural Language to SQL**: Converts user questions into PostgreSQL queries using OpenAI.
- ğŸ“Š **Conversational BI**: Supports both textual and graph-based data responses.
- ğŸ” **Streaming API (SSE)**: Delivers word-by-word responses in real-time.
- ğŸ“‚ **RAG-Powered**: Uses schema, sample queries, filters, and metrics embedded via ChromaDB.
- ğŸ§  **Embeddings**: Generates and stores vector embeddings from documents for context-aware responses.



## ğŸš€ Tech Stack

- **FastAPI** â€“ Lightweight, fast backend framework
- **PostgreSQL** â€“ Data source for BI queries
- **ChromaDB** â€“ Local vector store for embeddings
- **OpenAI API** â€“ SQL generation, response synthesis
- **Docker Compose** â€“ Containerized deployment
- **SSE/WebSocket** â€“ Real-time data streaming (SSE implemented)



## ğŸ› ï¸ Project Structure

# Conversational BI RAG Backend

A Python backend for a Conversational Business Intelligence (BI) system powered by Retrieval-Augmented Generation (RAG). This backend uses FastAPI, OpenAI, and ChromaDB to convert natural language questions into SQL queries and return insights as streaming text or graphs.

## ğŸ§  Key Features

- ğŸ” **Natural Language to SQL**: Converts user questions into PostgreSQL queries using OpenAI.
- ğŸ“Š **Conversational BI**: Supports both textual and graph-based data responses.
- ğŸ” **Streaming API (SSE)**: Delivers word-by-word responses in real-time.
- ğŸ“‚ **RAG-Powered**: Uses schema, sample queries, filters, and metrics embedded via ChromaDB.
- ğŸ§  **Embeddings**: Generates and stores vector embeddings from documents for context-aware responses.



## ğŸš€ Tech Stack

- **FastAPI** â€“ Lightweight, fast backend framework
- **PostgreSQL** â€“ Data source for BI queries
- **ChromaDB** â€“ Local vector store for embeddings
- **OpenAI API** â€“ SQL generation, response synthesis
- **Docker Compose** â€“ Containerized deployment
- **SSE/WebSocket** â€“ Real-time data streaming (SSE implemented)



## ğŸ› ï¸ Project Structure

# Conversational BI RAG Backend

A Python backend for a Conversational Business Intelligence (BI) system powered by Retrieval-Augmented Generation (RAG). This backend uses FastAPI, OpenAI, and ChromaDB to convert natural language questions into SQL queries and return insights as streaming text or graphs.

## ğŸ§  Key Features

- ğŸ” **Natural Language to SQL**: Converts user questions into PostgreSQL queries using OpenAI.
- ğŸ“Š **Conversational BI**: Supports both textual and graph-based data responses.
- ğŸ” **Streaming API (SSE)**: Delivers word-by-word responses in real-time.
- ğŸ“‚ **RAG-Powered**: Uses schema, sample queries, filters, and metrics embedded via ChromaDB.
- ğŸ§  **Embeddings**: Generates and stores vector embeddings from documents for context-aware responses.

## ğŸš€ Tech Stack

- **FastAPI** â€“ Lightweight, fast backend framework
- **PostgreSQL** â€“ Data source for BI queries
- **ChromaDB** â€“ Local vector store for embeddings
- **OpenAI API** â€“ SQL generation, response synthesis
- **Docker Compose** â€“ Containerized deployment
- **SSE/WebSocket** â€“ Real-time data streaming (SSE implemented)

## ğŸ› ï¸ Project Structure

conversational-bi-rag-backend/
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ main.py # FastAPI entrypoint,SSE streaming responses,SQL generation and execution
â”‚ â”œâ”€â”€ rag_retriever.py # Embedding-based RAG
â”‚â”œâ”€â”€ docs/ # RAG training documents
â”œâ”€â”€ Dockerfile # Backend Dockerfile
â”œâ”€â”€ data_loader.py # Loading open source order data to postgres
â”œâ”€â”€ docker-compose.yml # Full stack orchestration
â””â”€â”€ requirements.txt

## âš™ï¸ Setup Instructions

### 1. Clone the Repository
``` git clone https://github.com/haroonob/conversational-bi-rag-backend.git```
```cd conversational-bi-rag-backend```

## 2. Create .env File
```OPENAI_API_KEY=your-openai-key```

## 3. Run with Docker Compose
```docker compose up --build```

