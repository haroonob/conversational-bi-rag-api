# Conversational BI RAG Backend

A Python backend for a Conversational Business Intelligence (BI) system powered by Retrieval-Augmented Generation (RAG). This backend uses FastAPI, OpenAI, and ChromaDB to convert natural language questions into SQL queries and return insights as streaming text or graphs.

## 🧠 Key Features

- 🔍 **Natural Language to SQL**: Converts user questions into PostgreSQL queries using OpenAI.
- 📊 **Conversational BI**: Supports both textual and graph-based data responses.
- 🔁 **Streaming API (SSE)**: Delivers word-by-word responses in real-time.
- 📂 **RAG-Powered**: Uses schema, sample queries, filters, and metrics embedded via ChromaDB.
- 🧠 **Embeddings**: Generates and stores vector embeddings from documents for context-aware responses.



## 🚀 Tech Stack

- **FastAPI** – Lightweight, fast backend framework
- **PostgreSQL** – Data source for BI queries
- **ChromaDB** – Local vector store for embeddings
- **OpenAI API** – SQL generation, response synthesis
- **Docker Compose** – Containerized deployment
- **SSE/WebSocket** – Real-time data streaming (SSE implemented)



## 🛠️ Project Structure

    # Conversational BI RAG Backend

A Python backend for a Conversational Business Intelligence (BI) system powered by Retrieval-Augmented Generation (RAG). This backend uses FastAPI, OpenAI, and ChromaDB to convert natural language questions into SQL queries and return insights as streaming text or graphs.

## 🧠 Key Features

- 🔍 **Natural Language to SQL**: Converts user questions into PostgreSQL queries using OpenAI.
- 📊 **Conversational BI**: Supports both textual and graph-based data responses.
- 🔁 **Streaming API (SSE)**: Delivers word-by-word responses in real-time.
- 📂 **RAG-Powered**: Uses schema, sample queries, filters, and metrics embedded via ChromaDB.
- 🧠 **Embeddings**: Generates and stores vector embeddings from documents for context-aware responses.



## 🚀 Tech Stack

- **FastAPI** – Lightweight, fast backend framework
- **PostgreSQL** – Data source for BI queries
- **ChromaDB** – Local vector store for embeddings
- **OpenAI API** – SQL generation, response synthesis
- **Docker Compose** – Containerized deployment
- **SSE/WebSocket** – Real-time data streaming (SSE implemented)



## 🛠️ Project Structure

# Conversational BI RAG Backend

A Python backend for a Conversational Business Intelligence (BI) system powered by Retrieval-Augmented Generation (RAG). This backend uses FastAPI, OpenAI, and ChromaDB to convert natural language questions into SQL queries and return insights as streaming text or graphs.

## 🧠 Key Features

- 🔍 **Natural Language to SQL**: Converts user questions into PostgreSQL queries using OpenAI.
- 📊 **Conversational BI**: Supports both textual and graph-based data responses.
- 🔁 **Streaming API (SSE)**: Delivers word-by-word responses in real-time.
- 📂 **RAG-Powered**: Uses schema, sample queries, filters, and metrics embedded via ChromaDB.
- 🧠 **Embeddings**: Generates and stores vector embeddings from documents for context-aware responses.



## 🚀 Tech Stack

- **FastAPI** – Lightweight, fast backend framework
- **PostgreSQL** – Data source for BI queries
- **ChromaDB** – Local vector store for embeddings
- **OpenAI API** – SQL generation, response synthesis
- **Docker Compose** – Containerized deployment
- **SSE/WebSocket** – Real-time data streaming (SSE implemented)



## 🛠️ Project Structure

# Conversational BI RAG Backend

A Python backend for a Conversational Business Intelligence (BI) system powered by Retrieval-Augmented Generation (RAG). This backend uses FastAPI, OpenAI, and ChromaDB to convert natural language questions into SQL queries and return insights as streaming text or graphs.

## 🧠 Key Features

- 🔍 **Natural Language to SQL**: Converts user questions into PostgreSQL queries using OpenAI.
- 📊 **Conversational BI**: Supports both textual and graph-based data responses.
- 🔁 **Streaming API (SSE)**: Delivers word-by-word responses in real-time.
- 📂 **RAG-Powered**: Uses schema, sample queries, filters, and metrics embedded via ChromaDB.
- 🧠 **Embeddings**: Generates and stores vector embeddings from documents for context-aware responses.
